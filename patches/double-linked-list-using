Bottom: ed2ebe4daaf599c461c3d37f5dab0625efccade5
Top:    c6292c2ed4e718bb2d2ca41994ce422b2e6905ef
Author: Igor Stoppa <igor.stoppa@huawei.com>
Date:   2018-05-20 21:48:59 +0300

Double linked list using protected memory

In some cases, all the data needing protection can be allocated from a pool
in one go, as directly writable, then initialized and protected.
The sequence is relatively short and it's acceptable to leave the entire
data set unprotected.

In other cases, this is not possible, because the data will trickle over
a relatively long period of time, in a non predictable way, possibly for
the entire duration of hte operations.

For these cases, the safe approach is to have the memory already write
protected, when allocated. However, this will require replacing any
direct assignment with calls to rare_write().

The usual double linked list needs, therefore, to be replaced with a
derived variant that will replace direct writes, with rare_write().

This patch implements the most basic functionality.

Signed-off-by: Igor Stoppa <igor.stoppa@huawei.com>


---

diff --git a/include/linux/prot_list.h b/include/linux/prot_list.h
new file mode 100644
index 000000000000..90d6fa2441ef
--- /dev/null
+++ b/include/linux/prot_list.h
@@ -0,0 +1,102 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * prot_list.h: Header for Protectable Double Linked List
+ *
+ * (C) Copyright 2018 Huawei Technologies Co. Ltd.
+ * Author: Igor Stoppa <igor.stoppa@huawei.com>
+ */
+
+#ifndef _LINUX_PROT_LIST_H
+#define _LINUX_PROT_LIST_H
+
+#include <linux/pmalloc.h>
+#include <linux/list.h>
+#include <linux/kernel.h>
+
+struct prot_list_pool {
+	struct pmalloc_pool pool;
+};
+
+struct prot_head {
+	struct list_head list;
+};
+
+static inline struct prot_head *list_to_prot(struct list_head *list)
+{
+	return container_of(list, struct prot_head, list);
+}
+
+struct prot_list_pool
+*prot_list_create_custom_pool(size_t refill, unsigned short align_order);
+
+static inline
+struct prot_list_pool *prot_list_create_pool(void)
+{
+	return prot_list_create_custom_pool(PMALLOC_REFILL_DEFAULT,
+					    PMALLOC_ALIGN_ORDER_DEFAULT);
+}
+
+static inline void INIT_PROT_LIST_HEAD(struct prot_list_pool *pool,
+				       struct prot_head *list)
+{
+	struct prot_head head = {LIST_HEAD_INIT(list->list)};
+
+	pmalloc_rare_write(&pool->pool, list, &head,
+			   sizeof(struct prot_head));
+}
+
+static inline struct prot_head *PROT_LIST_HEAD(struct prot_list_pool *pool)
+{
+	struct prot_head *head;
+
+	head = pmalloc(&pool->pool, sizeof(struct prot_head));
+	if (WARN(!head, "Could not allocate protected list head."))
+		return NULL;
+	INIT_PROT_LIST_HEAD(pool, head);
+	return head;
+
+}
+
+#define prot_list_append(pool, head, src, node) \
+	__prot_list_add(pool, head, src, sizeof(*src), \
+			((uintptr_t)&(src)->node) - (uintptr_t)(src))
+
+#define	prot_list_prepend(pool, head, src, node)			\
+	__prot_list_add(pool,						\
+			list_to_prot((head)->list.prev),		\
+			(src), sizeof(*(src)),				\
+			((uintptr_t)&(src)->node) - (uintptr_t)(src))
+
+static inline bool __prot_list_add(struct prot_list_pool *pool,
+				   struct prot_head *head,
+				   void *src, size_t src_size,
+				   uintptr_t offset)
+{
+	void *dst;
+	bool retval;
+	struct prot_head *src_list;
+	void *p;
+
+	dst = pmalloc(&pool->pool, src_size);
+	if (WARN(!head, "Could not allocate protected list head."))
+		return false;
+	mutex_lock(&pool->pool.mutex);
+	src_list = src + offset;
+	src_list->list.prev = &head->list;
+	src_list->list.next = head->list.next;
+	retval = pmalloc_rare_write(&pool->pool, dst, src, src_size);
+	if (WARN(!retval, "Failed to init list element."))
+		goto out;
+	p = (void *)(offset + (uintptr_t)dst);
+	retval = pmalloc_rare_write(&pool->pool, &head->list.next->prev, &p,
+				      sizeof(p));
+	if (WARN(!retval, "Failed to hook to next element."))
+		goto out;
+	retval = pmalloc_rare_write(&pool->pool, &head->list.next, &p, sizeof(p));
+	if (WARN(!retval, "Failed to hook to previous element."))
+		goto out;
+out:
+	mutex_unlock(&pool->pool.mutex);
+	return retval;
+}
+#endif
diff --git a/lib/Makefile b/lib/Makefile
index ce20696d5a92..d949af6c1b2a 100644
--- a/lib/Makefile
+++ b/lib/Makefile
@@ -265,3 +265,4 @@ obj-$(CONFIG_GENERIC_LSHRDI3) += lshrdi3.o
 obj-$(CONFIG_GENERIC_MULDI3) += muldi3.o
 obj-$(CONFIG_GENERIC_CMPDI2) += cmpdi2.o
 obj-$(CONFIG_GENERIC_UCMPDI2) += ucmpdi2.o
+obj-$(CONFIG_PROTECTABLE_MEMORY) += prot_list.o
diff --git a/lib/prot_list.c b/lib/prot_list.c
new file mode 100644
index 000000000000..20eacbac6cad
--- /dev/null
+++ b/lib/prot_list.c
@@ -0,0 +1,23 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * prot_list.c: protected double linked list
+ *
+ * (C) Copyright 2018 Huawei Technologies Co. Ltd.
+ * Author: Igor Stoppa <igor.stoppa@huawei.com>
+ */
+
+#include <linux/prot_list.h>
+
+struct prot_list_pool *prot_list_create_custom_pool(size_t refill,
+						    unsigned short align_order)
+{
+	struct prot_list_pool *pool;
+
+	pool = kzalloc(sizeof(struct prot_list_pool), GFP_KERNEL);
+	if (WARN(!pool, "Could not allocate pool meta data."))
+		return NULL;
+	pmalloc_init_custom_pool(&pool->pool, refill, align_order,
+				 PMALLOC_AUTO_RW);
+	return pool;
+}
+EXPORT_SYMBOL(prot_list_create_custom_pool);
