Bottom: eb7f23a19bb21d558f550cacdcbc6cfedd762536
Top:    12820e15f2f3b2a62299f02f98f1266ef3586f8d
Author: Igor Stoppa <igor.stoppa@huawei.com>
Date:   2018-05-09 19:29:33 +0400

rewritable -> mode


---

diff --git a/include/linux/pmalloc.h b/include/linux/pmalloc.h
index 80b8aa19b53d..3887e571d1dc 100644
--- a/include/linux/pmalloc.h
+++ b/include/linux/pmalloc.h
@@ -47,12 +47,12 @@
 #define PMALLOC_SHIFT_RW_RO	0x08
 
 struct pmalloc_pool *pmalloc_create_custom_pool(size_t refill,
-						bool rewritable,
-						unsigned short align_order);
+						unsigned short align_order,
+						bool mode);
 
 /**
  * pmalloc_create_pool() - create a protectable memory pool
- * @rewritable: can the data be altered after protection
+ * @mode: can the data be altered after protection
  *
  * Shorthand for pmalloc_create_custom_pool() with default argument:
  * * refill is set to PMALLOC_REFILL_DEFAULT
@@ -62,11 +62,11 @@ struct pmalloc_pool *pmalloc_create_custom_pool(size_t refill,
  * * pointer to the new pool	- success
  * * NULL			- error
  */
-static inline struct pmalloc_pool *pmalloc_create_pool(bool rewritable)
+static inline struct pmalloc_pool *pmalloc_create_pool(bool mode)
 {
 	return pmalloc_create_custom_pool(PMALLOC_REFILL_DEFAULT,
-					  rewritable,
-					  PMALLOC_ALIGN_DEFAULT);
+					  PMALLOC_ALIGN_DEFAULT,
+					  mode);
 }
 
 
diff --git a/mm/pmalloc.c b/mm/pmalloc.c
index ca7f10b50b25..7e2ba1b03c67 100644
--- a/mm/pmalloc.c
+++ b/mm/pmalloc.c
@@ -34,9 +34,9 @@ static DEFINE_MUTEX(pools_mutex);
  * @refill: the minimum size to allocate when in need of more memory.
  *          It will be rounded up to a multiple of PAGE_SIZE
  *          The value of 0 gives the default amount of PAGE_SIZE.
- * @rewritable: can the data be altered after protection
  * @align_order: log2 of the alignment to use when allocating memory
  *               Negative values give ARCH_KMALLOC_MINALIGN
+ * @mode: can the data be altered after protection
  *
  * Creates a new (empty) memory pool for allocation of protectable
  * memory. Memory will be allocated upon request (through pmalloc).
@@ -46,8 +46,8 @@ static DEFINE_MUTEX(pools_mutex);
  * * NULL			- error
  */
 struct pmalloc_pool *pmalloc_create_custom_pool(size_t refill,
-						bool rewritable,
-						unsigned short align_order)
+						unsigned short align_order,
+						bool mode)
 {
 	struct pmalloc_pool *pool;
 
@@ -56,7 +56,7 @@ struct pmalloc_pool *pmalloc_create_custom_pool(size_t refill,
 		return NULL;
 
 	pool->refill = refill ? PAGE_ALIGN(refill) : DEFAULT_REFILL_SIZE;
-	pool->rewritable = rewritable;
+	pool->mode = mode;
 	pool->align = 1UL << align_order;
 	mutex_init(&pool->mutex);
 
@@ -80,7 +80,7 @@ static int grow(struct pmalloc_pool *pool, size_t min_size)
 		return -ENOMEM;
 
 	area = find_vmap_area((unsigned long)addr);
-	tag_area(area, pool->rewritable);
+	tag_area(area, pool->mode);
 	pool->offset = get_area_pages_size(area);
 	llist_add(&area->area_list, &pool->vm_areas);
 	return 0;
@@ -193,7 +193,7 @@ bool pmalloc_rare_write(struct pmalloc_pool *pool, const void *destination,
 	 * that are not supposed to be modifiable.
 	 */
 	mutex_lock(&pool->mutex);
-	if (WARN(pool->rewritable != PMALLOC_RW,
+	if (WARN(pool->mode != PMALLOC_RW,
 		 "Attempting to modify non rewritable pool"))
 		goto out;
 	area = pool_get_area(pool, destination, n_bytes);
@@ -222,7 +222,7 @@ void pmalloc_make_pool_ro(struct pmalloc_pool *pool)
 	struct vmap_area *area;
 
 	mutex_lock(&pool->mutex);
-	pool->rewritable = false;
+	pool->mode = false;
 	llist_for_each_entry(area, pool->vm_areas.first, area_list)
 		protect_area(area);
 	mutex_unlock(&pool->mutex);
diff --git a/mm/pmalloc_helpers.h b/mm/pmalloc_helpers.h
index 538e37564f8f..8a0113d1bfba 100644
--- a/mm/pmalloc_helpers.h
+++ b/mm/pmalloc_helpers.h
@@ -26,7 +26,7 @@ struct pmalloc_pool {
 	size_t refill;
 	size_t offset;
 	size_t align;
-	bool rewritable;
+	bool mode;
 };
 
 #define VM_PMALLOC_PROTECTED_MASK (VM_PMALLOC | VM_PMALLOC_PROTECTED)
@@ -42,9 +42,9 @@ static __always_inline unsigned long area_flags(struct vmap_area *area)
 	return area->vm->flags & VM_PMALLOC_MASK;
 }
 
-static __always_inline void tag_area(struct vmap_area *area, bool rewritable)
+static __always_inline void tag_area(struct vmap_area *area, bool mode)
 {
-	if (rewritable == PMALLOC_RW)
+	if (mode == PMALLOC_RW)
 		area->vm->flags |= VM_PMALLOC_REWRITABLE_MASK;
 	else
 		area->vm->flags |= VM_PMALLOC;
